## 目录
- [10月13~10月19](#10月1310月19)
- [10月6~10月12](#10月610月12)
- [9月29~10月5](#9月2910月5)
- [9月22~9月28](#9月229月28)
- [9月15~9月21](#9月159月21)
- [9月8~9月14](#9月89月14)
- [9月1~9月7](#9月19月7)
- [8月25~8月31](#8月258月31)
- [8月18~8月24](#8月188月24)
- [8月11~8月17](#8月118月17)
- [8月4~8月10](#8月48月10)
- [7月28~8月3](#7月288月3)
- [7月21~7月27](#7月217月27)
- [7月14~7月20](#7月147月20)
- [7月7~7月13](#7月77月13)
- [6月30~7月6](#6月307月6)
- [6月23~6月29](#6月236月29)
- [6月16~6月22](#6月166月22)
- [6月9~6月15](#6月96月15)
- [6月2~6月8](#6月26月8)
<br><br>

## 10月13~10月19
### 10月16日
- 【开源】百度发布PaddleOCR-VL-0.9B多模态文档解析模型，仅0.9B参数刷新多个权威评测记录，支持109种语言，能够精准识别图片中的文本、手写汉字、表格、公式和图表等复杂元素，每秒处理1881个Token，推理速度较MinerU提升14.2%。详情请参见 https://www.modelscope.cn/models/PaddlePaddle/PaddleOCR-VL

### 10月15日
- 【闭源】字节豆包发布doubao-seed-1-6-lite-251015，支持深度思考（可手动关闭、可调节思考长度），具备文本生成、图片理解、视频理解、工具调用能力。详情请参见 https://www.volcengine.com/docs/82379/1874969
- 【闭源】阿里发布qwen3-vl-flash-2025-10-15，Qwen3系列小尺寸视觉理解模型，实现思考模式和非思考模式有效融合，效果更优、响应速度更快。详情请参见 https://help.aliyun.com/zh/model-studio/vision
- 【闭源】谷歌发布Veo 3.1和3.1 Fast公开预览版，支持延长视频、参考最多三张图片生成视频、提供首尾帧控制，新增4秒、6秒、8秒时长选项。详情请参见 https://ai.google.dev/gemini-api/docs/video#veo-3.1
- 【闭源】Anthropic发布Claude Haiku 4.5，最快且最智能的Haiku模型，具有近前沿性能，适用于实时应用、高容量处理和成本敏感型部署。详情请参见 https://docs.claude.com/en/docs/about-claude/models

### 10月14日
- 【闭源】腾讯混元发布hunyuan-translation翻译模型，支持33种语种互译和5种民族语言互译，同尺寸模型中效果最优，WMT25比赛30种语种获得第一，开源测试集Flores200效果领先。详情请参见 https://cloud.tencent.com/document/product/1729/104753

### 10月13日
- 【开源】阿里开源qwen3-vl-8b-thinking、qwen3-vl-8b-instruct，Qwen3-VL系列 8B 的Dense模型，占用显存更低，能够完成多模态理解与推理；支持长视频长文档等超长上下文、视觉2D/3D定位；全面空间感知与万物识别能力。详情请参见 https://modelscope.cn/collections/Qwen3-VL-5c7a94c8cb144b
<br><br>


## 10月6~10月12
### 10月10日
- 【闭源】阶跃星辰step-tts-mini新增三款精品音色：气质温婉、活力轻快、Energetic-Confident（英文音色）。详情请参见 https://platform.stepfun.com/docs/guide/tts#step-tts-mini

### 10月7日
- 【闭源】OpenAI 推出Sora2模型后，不久就正式上线视频生成模型 Sora 2 和 Sora 2 Pro API。详细内容请参见： https://platform.openai.com/docs/guides/video-generation
- 【闭源】谷歌发布Gemini 2.5电脑使用预览版，支持通过API控制电脑操作。详情请参见 https://ai.google.dev/gemini-api/docs/computer-use

### 10月6日
- 【闭源】OpenAI 正式上线 GPT-5 pro 模型API。GPT-5 pro 仅通过 Responses API 提供，最大输出 Token 数量为272,000，并且其上下文限制为400,000 Token。知识截止日期为2024年9月30日。详细请参见： https://platform.openai.com/docs/models/gpt-5-pro
<br><br>


## 9月29~10月5
### 10月4日
- 【开源】百灵大模型团队发布Ling-1T旗舰级非思考模型，总共1万亿参数，每个token约500亿活跃参数，支持128K上下文长度，在多个复杂推理基准上达SOTA性能。详情请参见 https://modelscope.cn/models/inclusionAI/Ling-1T

### 10月2日
- 【闭源】谷歌正式发布Gemini 2.5 Flash图片生成模型。详情请参见 https://ai.google.dev/gemini-api/docs/image-generation

### 9月30日
- 【开源】智谱发布GLM-4.6，GLM系列最强代码模型，较GLM-4.5代码能力提升27%，在真实编程、长上下文处理、推理能力等方面全面提升。详情请参见 https://www.modelscope.cn/models/ZhipuAI/GLM-4.6

### 9月29日
- 【闭源】Anthropic发布Claude Sonnet 4.5，在复杂智能代理和编码任务中表现最佳，在大多数任务中具有最高智能水平。详情请参见 https://docs.claude.com/en/docs/about-claude/models/whats-new-sonnet-4.5
- 【开源】DeepSeek发布DeepSeek-V3.2-Exp实验性版本，引入DeepSeek Sparse Attention稀疏注意力机制，显著提升长上下文处理效率。详情请参见 https://modelscope.cn/models/deepseek-ai/DeepSeek-V3.2-Exp
<br><br>


## 9月22~9月28
### 9月28日
- 【开源】腾讯混元发布混元图像3.0（HunyuanImage 3.0），首个工业级原生多模态生图模型，参数规模80B，目前效果最好、参数量最大的开源生图模型。详情请参见https://modelscope.cn/models/Tencent-Hunyuan/HunyuanImage-3.0

### 9月26日
- 【闭源】腾讯混元发布hunyuan-turbos-20250926，理科类平均提升10.9%（数学能力提升13.8%，逻辑推理提升12.3%），文科类写作、知识问答、Agent领域提升约2%。详情请参见https://cloud.tencent.com/document/product/1729/104753

### 9月25日
- 【闭源】谷歌发布Gemini Robotics-ER 1.5预览版模型，专为机器人技术应用设计。详情请参见https://ai.google.dev/gemini-api/docs/robotics-overview
- 【闭源】谷歌发布gemini-2.5-flash-preview-09-2025和gemini-2.5-flash-lite-preview-09-2025两款预览模型。详情请参见https://ai.google.dev/gemini-api/docs/models

### 9月23日
- 【闭源｜语音识别】阿里发布语音识别模型fun-asr-realtime，集成创新RAG技术，支持大规模热词自定义、ITN规范化、标点预测等，显著提升识别准确率与语境贴合度，支持中英文自由切换，具备更强噪声鲁棒性。详情请参见https://help.aliyun.com/zh/model-studio/real-time-speech-recognition
- 【闭源｜多模态向量】阿里发布多模态向量模型tongyi-embedding-vision-plus、tongyi-embedding-vision-flash，基于Qwen系列大语言模型构建，增强视觉向量化能力，支持文字、图像、视频三种模态。详情请参见https://help.aliyun.com/zh/model-studio/embedding
- 【闭源｜代码】阿里发布代码模型qwen3-coder-plus-2025-09-23，基于Qwen3，在下游任务效果、工具调用鲁棒性及代码安全性方面较上一版本提升。详情请参见https://help.aliyun.com/zh/model-studio/qwen-coder
- 【闭源｜文生图】阿里发布文生图模型qwen-image-plus，复杂文本渲染突出，支持中英文及复杂图文混合布局，价格优于qwen-image。详情请参见https://help.aliyun.com/zh/model-studio/qwen-image-api
- 【闭源｜文生文】阿里发布文生文模型qwen3-max、qwen3-max-2025-09-23，相较preview版在智能体编程与工具调用方向专项升级，达领域SOTA水平。详情请参见https://help.aliyun.com/zh/model-studio/models
- 【闭源｜视觉推理】阿里发布视觉推理模型qwen3-vl-plus、qwen3-vl-plus-2025-09-23，融合思考/非思考模式，视觉智能体能力世界顶尖，视觉编码、空间感知、多模态思考全面升级。详情请参见https://help.aliyun.com/zh/model-studio/vision
- 【闭源｜文生图】阿里发布文生图模型wan2.5-t2i-preview，取消单边限制，总像素面积与宽高比约束内可自由选尺寸。详情请参见https://help.aliyun.com/zh/model-studio/text-to-image-v2-api-reference
- 【闭源｜图像编辑】阿里发布图像编辑模型wan2.5-i2i-preview，支持文本、单图或多图输入，实现主体一致性编辑、多图融合与组图生成。详情请参见https://help.aliyun.com/zh/model-studio/wan2-5-image-edit-api-reference
- 【闭源｜文生视频】阿里发布文生视频模型wan2.5-t2v-preview，新增音频能力，支持自动配音或自定义音频文件，实现音画同步。详情请参见https://help.aliyun.com/zh/model-studio/text-to-video-api-reference
- 【闭源｜图生视频】阿里发布图生视频模型wan2.5-i2v-preview，新增音频能力，支持自动配音或自定义音频文件，实现音画同步。详情请参见https://help.aliyun.com/zh/model-studio/image-to-video-api-reference
- 【闭源】谷歌发布gemini-2.5-flash-native-audio-preview-09-2025，Live API原生音频模型，改进函数调用与语音截断处理。详情请参见https://ai.google.dev/gemini-api/docs/live-guide
- 【开源】阿里开源Qwen3-VL-235B-A22B-Instruct与Qwen3-VL-235B-A22B-Thinking，迄今最强Qwen视觉语言模型，支持256K上下文可扩展至1M，新增视觉代理与视觉编码能力。详情请参见https://modelscope.cn/models/Qwen/Qwen3-VL-235B-A22B-Instruct与https://modelscope.cn/models/Qwen/Qwen3-VL-235B-A22B-Thinking

### 9月22日
- 【闭源｜全模态】阿里发布qwen3-omni-flash、qwen3-omni-flash-realtime模型，Qwen3系列多模态模型，高效理解文本、图像、音频、视频，支持119种语言文本交互，具备卓越指令跟随与系统提示定制能力，可用于语音助手、多媒体分析、内容创作等。详情请参见https://help.aliyun.com/zh/model-studio/qwen-omni
- 【闭源｜语音合成】阿里通义团队发布qwen3-tts-flash、qwen3-tts-flash-realtime，最新离线语音合成大模型，17种高表现力拟人音色，低延迟高稳定合成，支持多语言与方言。详情请参见https://help.aliyun.com/zh/model-studio/qwen-tts
- 【闭源｜音视频翻译】阿里发布音视频实时翻译模型qwen3-livetranslate-flash-realtime-2025-09-22，可识别18种语言并实时翻译为10种语言音频。详情请参见https://help.aliyun.com/zh/model-studio/qwen3-livetranslate-flash-realtime
- 【开源】美团发布LongCat-Flash-Thinking高效推理模型，在逻辑、数学、代码、智能体等领域达全球开源SOTA，国内首个同时具备“深度思考+工具调用”与“非形式化+形式化”推理能力的模型。详情请参见https://github.com/meituan-longcat/LongCat-Flash-Thinking
<br><br>


## 9月15~9月21
### 9月19日
- 【闭源】百度发布ERNIE-4.5-21B-A3B-Thinking轻量级深度思考模型，专注于提升推理质量和深度，在逻辑推理、数学、科学、编码和文本生成等任务上性能显著提升。详情请参见https://cloud.baidu.com/doc/WENXINWORKSHOP/s/flxu4ej5u

### 9月17日
- 【开源】通义千问团队全面开源Tongyi-DeepResearch-30B-A3B代理大语言模型，专门用于长期、深度信息搜索任务，在代理搜索基准测试中展示先进性能。模型链接及详情请参见https://modelscope.cn/models/iic/Tongyi-DeepResearch-30B-A3B
- 【开源】阿里通义万相发布Wan2.2-Animate-14B数字人生成模型，支持Animation（动作捕捉）和Replacement（角色替换）两种模式，实现静态图像到动画角色的转换。模型链接及详情请参见https://modelscope.cn/models/Wan-AI/Wan2.2-Animate-14B

### 9月15日
- 【闭源】OpenAI发布GPT-5-codex，专为代理编程优化的GPT-5变体，支持快速交互式编辑和长期独立任务，前端/UI工作可接受图像或截图输入。详情请参见相关文档https://openai.com/index/introducing-upgrades-to-codex/
<br><br>


## 9月8~9月14
### 9月12日
- 【开源】 通义千问发布Qwen3-Next，融合混合注意力机制、高稀疏度MoE及多token预测。Qwen3-Next-80B-A3B 在“思考模式”和“非思考模式”下的性能均与规模更大的 Qwen3-235B-A22B-2507 相当，同时在推理速度上显著提升，尤其在长上下文场景中表现更为突出。详情请参见https://modelscope.cn/collections/Qwen3-Next-c314f23bd0264a

### 9月11日
- 【闭源】 推理模型qwen-plus-2025-09-11属于 Qwen3 系列模型，相较于qwen-plus-2025-07-28，在思考模式下提升了指令遵循能力、总结回复更加精简，详见https://help.aliyun.com/zh/model-studio/deep-thinking。在非思考模式下中文理解与逻辑推理能力得到增强，详见https://help.aliyun.com/zh/model-studio/text-generation。

### 9月10日
- 【开源】 腾讯混元发布混元图像2.1，支持最长1000个tokens提示词，具备精细文字控制能力，原生高效生成2K图像，采用17B参数单/双流DiT模型。详情请参见https://modelscope.cn/models/Tencent-Hunyuan/HunyuanImage-2.1

### 9月9日
- 【闭源】 谷歌发布Veo 3和Veo 3 Fast正式版，价格更低，新增宽高比、分辨率和种子选项。详情请参见https://ai.google.dev/gemini-api/docs/video

### 9月8日
- 【闭源】 阿里发布CosyVoice-v3-plus和CosyVoice-v3语音合成模型，在自然度、音质、韵律、情感表现力上显著提升。详情请参见https://help.aliyun.com/zh/model-studio/text-to-speech
- 【开源】 B站语音团队发布IndexTTS2，引入音色与情感解耦建模机制，支持分别指定音色参考与情感参考，实现更灵活的语音合成控制。详情请参见：https://www.modelscope.cn/models/IndexTeam/IndexTTS-2
<br><br>


## 9月1~9月7
### 9月5日
- 【闭源】 阿里发布qwen3-max-preview，基于Qwen3的预览版模型，相较Qwen 2.5系列通用能力大幅提升，模型知识幻觉更少。详情请参见https://help.aliyun.com/zh/model-studio/model-announcements
- 【开源】 月之暗面更新Kimi-K2-Instruct-0905，MoE架构语言模型，320亿激活参数，总共1万亿参数，上下文窗口从128k扩展到256k。详情请参见https://modelscope.cn/models/moonshotai/Kimi-K2-Instruct-0905

### 9月3日
- 【开源】 腾讯混元发布HunyuanWorld-Voyager，业界首个支持原生3D重建的超长漫游世界模型，荣登斯坦福WorldScore世界模型排行榜综合能力榜首。详情请参见https://modelscope.cn/models/Tencent-Hunyuan/HunyuanWorld-Voyager

### 9月2日
- 【开源】 腾讯混元发布Hunyuan-MT-7B翻译模型，在WMT25参赛的31种语言中有30种获得第一名，支持33个语种、5种民汉语言/方言互译。详情请参见https://modelscope.cn/models/Tencent-Hunyuan/Hunyuan-MT-7B

### 9月1日
- 【开源】 美团发布LongCat-Flash-Chat语言模型，总参数量5600亿，采用MoE架构，激活186-313亿参数，实现每秒超过100个token的高效推理。详情请参见https://modelscope.cn/models/meituan-longcat/LongCat-Flash-Chat
<br><br>


## 8月25~8月31
### 8月28日
- 【闭源】 MiniMax发布Hailuo-02模型首尾帧视频生成功能，新增"last_frame_image"参数控制视频生成的起始与结束画面。详情请参见 https://platform.minimaxi.com/document/video_generation
- 【开源】 腾讯混元开源HunyuanVideo-Foley端到端视频音效生成模型，只需输入视频和文字就能为视频匹配电影级音效，让AI视频告别无声时代。详情请参见 https://modelscope.cn/models/Tencent-Hunyuan/HunyuanVideo-Foley

### 8月26日
- 【闭源】 谷歌推出Gemini 2.5 Image Preview原生图像生成模型，提供更强的图像生成能力。详情请参见https://ai.google.dev/gemini-api/docs/models#gemini-2.5-flash-image-preview
- 【闭源】 XAI发布首个代码模型Grok Code Fast 1，专为代码编辑器设计使用。详情请参见https://docs.x.ai/docs/release-notes#grok-code-fast-1-is-released
- 【开源】 阿里通义万相开源Wan2.2-S2V音频驱动视频生成模型（14B参数），可生成影视级质感的高质量视频，支持全身与半身角色生成。详情请参见https://www.modelscope.cn/studios/Wan-AI/Wan2.2-S2V
- 【开源】 微软发布VibeVoice-1.5B文本转语音模型，支持单次会话生成90分钟连续自然语音，并发合成4个不同说话人。详情请参见 https://www.modelscope.cn/models/microsoft/VibeVoice-1.5B
- 【开源】 面壁智能发布MiniCPM-V 4.5多模态模型（8B参数），首个具备"高刷"视频理解能力的多模态模型，性能超过Qwen2.5-VL 72B。详情请参见 https://www.modelscope.cn/models/OpenBMB/MiniCPM-V-4_5


## 8月18~8月24
### 8月22日
- 【闭源】 阿里发布qwen-mt-image通义千问图像翻译模型，支持将11种语言图片的文字翻译成中文或英文，能精准保留原始排版与内容信息，并提供术语定义、敏感词过滤、图像主体检测等功能。详情请参见https://help.aliyun.com/zh/model-studio/qwen-mt-image-api
- 【闭源】 阿里发布qwen-deep-research通义千问深入研究模型，它可以拆解复杂问题、结合互联网搜索进行推理分析并生成研究报告。详情请见https://help.aliyun.com/zh/model-studio/qwen-deep-research
- 【闭源】 阿里发布fun-asr语音识别模型（稳定版和快照版），FunASR是通义实验室推出的端到端语音识别大模型，具备卓越的上下文感知和高精度转写能力，支持中英文录音文件识别。详情请参见https://help.aliyun.com/zh/model-studio/recording-file-recognition

### 8月21日
- 【开源】 DeepSeek发布DeepSeek-V3.1后训练模型，在DeepSeek-V3.1-Base基础上进行后训练优化，其基座 checkpoint 通过两阶段长上下文扩展方法构建。详情请参见https://modelscope.cn/models/deepseek-ai/DeepSeek-V3.1
- 【开源】 字节跳动Seed团队发布Seed-OSS系列开源大型语言模型，使用12T token训练，提供强大的长上下文、推理、代理和通用功能。包含三个版本：
  - Seed-OSS-36B-Base（含合成数据）：https://modelscope.cn/models/ByteDance-Seed/Seed-OSS-36B-Base
  - Seed-OSS-36B-Base-woSyn（不含合成数据）：https://modelscope.cn/models/ByteDance-Seed/Seed-OSS-36B-Base-woSyn
  - Seed-OSS-36B-Instruct：https://modelscope.cn/models/ByteDance-Seed/Seed-OSS-36B-Instruct

### 8月20日
- 【闭源】 阿里发布qwen-tts-vc-realtime-2025-08-20语音合成模型，qwen-tts-realtime模型的2025年8月20日快照版本，支持声音复刻与多语种语音合成。详情请参见https://help.aliyun.com/zh/model-studio/qwen-tts-realtime
- 【开源】 DeepSeek发布DeepSeek-V3.1-Base基础模型，支持思考模式和非思考模式的混合模型。详情请参见https://modelscope.cn/models/deepseek-ai/DeepSeek-V3.1-Base

### 8月19日
- 【开源】 阿里发布Qwen-Image-Edit通义千问图像编辑模型，基于20B的Qwen-Image模型进一步训练，支持语义/外观双重编辑和精准的中英双语文字编辑，在多个公开基准测试中均获得SOTA性能。详情请参见https://www.modelscope.cn/models/Qwen/Qwen-Image-Edit

### 8月18日
- 【闭源】谷歌正式发布网址上下文工具，该工具可提供网址作为提示的额外上下文。对将网址上下文与gemini-2.0-flash模型搭配使用的支持将在1个月后停止。详情请参见https://ai.google.dev/gemini-api/docs/url-context?hl=zh-cn
<br><br>


## 8月11~8月17
### 8月15日
- 【开源】 腾讯发布Hunyuan-GameCraft 1.0，用于游戏环境高动态交互视频生成的新颖框架。将键盘鼠标输入统一到共享摄像机表示空间，采用混合历史条件训练策略，在超过100个AAA游戏的百万级游戏录制数据集上进行训练。详情请参见https://modelscope.cn/models/Tencent-Hunyuan/Hunyuan-GameCraft-1.0/summary

### 8月14日
- 【闭源】 谷歌正式发布Imagen 4系列模型（Ultra、标准版、快速版），支持2K分辨率生成。详情请参见https://ai.google.dev/gemini-api/docs/imagen?hl=zh-cn

### 8月13日
- 【闭源】 阿里发布qwen-vl-max-2025-08-13视觉理解模型，提升多语言处理和文本渲染能力。详情请参见 https://help.aliyun.com/zh/model-studio/vision/ 
- 【开源】 Skywork AI发布Matrix-Game 2.0，首个开源实时长序列交互世界模型，支持25 FPS视频生成。详情请参见https://modelscope.cn/models/Skywork/Matrix-Game-2.0/summary

### 8月12日
- 【闭源】 Anthropic推出Claude Sonnet 4的100万令牌上下文窗口，增加5倍容量，支持处理超过75,000行代码。详情请参见https://docs.anthropic.com/en/docs/build-with-claude/context-windows#1m-token-context-window
- 【开源】百川智能发布Baichuan-M2-32B医疗增强推理模型，基于Qwen2.5-32B构建，采用大型验证系统和多阶段强化学习策略，在HealthBench上超越所有开源模型并达到接近GPT-5的医疗能力。详情请见https://modelscope.cn/models/baichuan-inc/Baichuan-M2-32B/summary

### 8月11日
- 【闭源】 阿里发布wan2.2-i2v-flash万相2.2极速版模型，相较2.1模型在画面细节表现和运动稳定性方面均有显著提升，生成速度提升达50%。详情请参见 https://help.aliyun.com/zh/model-studio/image-to-video-api-reference/
- 【开源】 智谱AI发布GLM-4.5V视觉语言模型，基于GLM-4.5-Air（106B参数，12B激活），在42个公开视觉多模态榜单中达到同级开源模型SOTA性能，支持图像推理、视频理解、GUI任务及思考模式开关。详情请参见https://modelscope.cn/models/ZhipuAI/GLM-4.5V/summary
<br><br>


## 8月4~8月10
### 8月8日
- 【闭源】搜索结果内容块现在已在 Anthropic API 和 Google Cloud 的 Vertex AI 上全面推出。此功能能够为具有适当来源归属的 RAG 应用实现自然引用。不再需要 2025 年 6 月 9 日的 beta 首头部 search-results-2025-06-09。更多内容请查看搜索结果文档https://docs.anthropic.com/en/docs/build-with-claude/search-results。

### 8月7日
- 【闭源】谷歌gemini图像转视频生成中的允许成人内容设置现在已在受限制地区提供。详情请参见 Veo 页面https://ai.google.dev/gemini-api/docs/video?example=dialogue#veo-model-parameters。
- 【闭源】OpenAI发布新一代旗舰模型GPT-5（也包含mini/nano两款轻量模型），GPT-5也是所有已登录用户的新型默认模型。它简化了 ChatGPT，将其整合为一个自动切换的系统，将我们之前各模型的优势集于一身，成为一个智能且高效的新模型。所有 ChatGPT 计划的用户均可使用 GPT-5 。付费计划（Plus、Pro、Team）的用户可以使用模型选择器，能够手动选择 GPT-5 或 GPT-5 Thinking。Pro 和 Team 计划的用户可使用 GPT-5 Thinking Pro，虽然思考耗时稍长，但能为复杂任务提供所需的高精准度。了解更多关于 ChatGPT 中 GPT-5 的信息https://help.openai.com/en/articles/11909943。

### 8月6日
- 【闭源】MiniMax语音模型Speech 2.5发布，新一代语音生成模型，极致相似度，支持更多语种

### 8月5日
- 【开源】OpenAI 正式开源gpt-oss-120b / 20b 系列大模型，专为强大的推理、代理任务和多用途开发场景设计，单卡 H100 或 16 GB 内存可实现本地部署，支持可调推理深度、完整思维链、函数调用、网页浏览及 LoRA 微调，两款模型情况如下：gpt-oss-120b —— 适用于生产环境、通用目的和高推理需求的场景，可以装入单个 H100 GPU（117B 参数，其中 5.1B 激活参数）；gpt-oss-20b —— 适用于低延迟以及本地或特定用途的场景（21B 参数，其中 3.6B 激活参数）。模型链接：[gpt-oss-120b](https://modelscope.cn/models/openai-mirror/gpt-oss-120b)，[gpt-oss-20b](https://modelscope.cn/models/openai-mirror/gpt-oss-20b)
- 【闭源】Anthropic推出了 Claude Opus 4.1，这是对 Claude Opus 4 的一次渐进式更新，具有增强的能力和性能改进。更多内容请查看模型和定价文档https://docs.anthropic.com/en/docs/about-claude/models。

### 8月4日
- 【开源|图像生成】通义千问团队开源了首个图像生成基础模型 Qwen-Image，一个20B的MMDiT模型，展示其在复杂文本渲染和精确图像编辑方面取得的显著进展，模型主要特性包括：卓越的文本渲染能力: Qwen-Image 在复杂文本渲染方面表现出色，支持多行布局、段落级文本生成以及细粒度细节呈现。无论是英语还是中文，均能实现高保真输出；一致性的图像编辑能力（即将推出）: 通过增强的多任务训练范式，Qwen-Image 在编辑过程中能出色地保持编辑的一致性；强大的跨基准性能表现: 在多个公开基准测试中的评估表明，Qwen-Image 在各类生成与编辑任务中均获得SOTA，是一个强大的图像生成基础模型。目前魔搭社区AIGC专区已支持Qwen-Image的在线推理、训练。模型链接：https://www.modelscope.cn/models/Qwen/Qwen-Image。
<br><br>


## 7月28~8月3
### 8月1日
- 【闭源】Kimi K2 高速版模型 kimi-k2-turbo-preview 正式发布。（注：kimi-k2为开源，但kimi-k2-turbo没有对应的开源版本）

### 7月31日
- 【开源】阶跃星辰发布step-3模型，该模型拥有强大的视觉感知和复杂推理能力，可准确完成领域的复杂知识理解、数学与现实信息的交叉分析，以及日常生活中的各类视觉分析问题。详情见https://platform.stepfun.com/docs/llm/reasoning。
- 【闭源】谷歌发布Veo 3预览版模型，针对Veo 3预览版模型推出了图像转视频功能，并发布了Veo 3 Fast预览版模型，进一步提升生成效率。Veo 3详细请访问https://ai.google.dev/gemini-api/docs/video?hl=zh-cn&example=dialogue。

### 7月30日
- 【开源】腾讯发布端侧混合推理模型：Hunyuan-0.5B、Hunyuan-1.8B、Hunyuan-4B、Hunyuan-7B，这是腾讯开源的高效大语言模型系列，设计用于多样化计算环境的灵活部署，支持快慢思维双模式推理、256K超长上下文理解，采用分组查询注意力(GQA)机制实现高效推理。详情见https://modelscope.cn/models/Tencent-Hunyuan/Hunyuan-1.8B-Instruct

### 7月29日
- 【闭源】OpenAI推出ChatGPT Study Mode学习模式功能，这是一种新的学习体验，通过苏格拉底式提问引导理解、个性化响应和开放式反馈检查，帮助用户建立对任何主题的深入理解。目前面向Free、Plus、Pro和Teams用户开放。官方介绍：https://help.openai.com/en/articles/6825453-chatgpt-release-notes

### 7月28日
- 【闭源】阿里发布qwen-flash-2025-07-28、qwen3-coder-flash-2025-07-28
- 【闭源】阿里发布wan2.2-i2v-plus图生视频模型，相较2.1模型，新版本在画面细节表现和运动稳定性方面均有显著提升，生成速度提升达50%。详细信息，请访问https://help.aliyun.com/zh/model-studio/image-to-video-api-reference。
- 【闭源】阿里发布wan2.2-t2v-plus文生视频模型，新版本在画面细节表现和运动稳定性方面均有显著提升，生成速度提升达50%。详细信息见https://help.aliyun.com/zh/model-studio/text-to-video-api-reference。
- 【闭源】阿里发布wan2.2-t2i-flash、wan2.2-t2i-plus文生图模型，相较2.1模型，新版本在创意性、稳定性、写实质感上全面升级，生成速度提升达50%。详细请见https://help.aliyun.com/zh/model-studio/text-to-image-v2-api-reference。
- 【开源】智谱发布GLM-4.5系列模型，GLM-4.5拥有3550亿总参数和320亿激活参数，GLM-4.5-Air采用更紧凑设计，1060亿总参数和120亿激活参数。两个模型都是混合推理模型，提供复杂推理和工具使用的思维模式，以及即时响应的非思维模式。模型的相关详细介绍请见：https://docs.z.ai/guides/llm/glm-4.5
<br><br>


## 7月21~7月27
### 7月27日
- 【开源|多模态生成】腾讯发布HunyuanWorld-1.0，这是首个开源的沉浸式3D世界生成模型，支持从文字或图片生成可漫游、可交互的360度虚拟世界。如需了解更多信息，请访问https://3d-models.hunyuan.tencent.com/world/

### 7月25日
- 【闭源】科大讯飞发布星火X1的升级版本xunfei-spark-x1-0725，基于全国产算力训练的深度推理大模型，在数学运算、逻辑推理、幻觉治理等方面显著提升，支持130+语种，详细见官方介绍https://xinghuo.xfyun.cn/sparkapi。
- 【开源】阿里发布Qwen3-235B-A22B-Thinking-2507，是千问3-235B-A22B的思维增强版本，在逻辑推理、数学、科学、编码等推理任务上显著提升，支持256K长上下文理解。如需了解更多信息，请访问https://modelscope.cn/models/Qwen/Qwen3-235B-A22B-Thinking-2507/summary。

### 7月24日
- 【开源】无问芯穹发布Megrez2-3x7B-A3B-Preview，这是专为终端设备设计的MoE架构大模型，训练数据量5T Tokens，如需了解更多信息，请访问https://modelscope.cn/models/InfiniAI/Megrez2-3x7B-A3B-Preview/summary。
- 【开源】上海人工智能实验室发布开源多模态科学推理模型Intern-S1，基于235B MoE语言模型和6B视觉编码器构建，在5T多模态数据上预训练。如需了解更多信息，请访问https://modelscope.cn/models/Shanghai_AI_Laboratory/Intern-S1/summary。

### 7月23日
- 【闭源|多模态融合】商汤发布SenseNova-V6.5-Pro、SenseNova-V6.5-Turbo，这是日日新-融合模态模型的最新版本更新，专注于增强推理能力和提升训练效率。如需了解更多信息，请访问模型页面https://console.sensecore.cn/micro/help/docs/model-as-a-service/nova/model/fusionllm/FusionLLMs/。
- 【开源】阿里发布Qwen3-Coder-480B-A35B-Instruct，该模型在智能体编程、代理浏览器使用等基础编码任务上表现卓越，原生支持256K上下文并可扩展至1M，优化了对仓库规模的理解，支持Qwen Code、CLINE等多数平台的代理编码。如需了解更多信息，请访问https://modelscope.cn/models/Qwen/Qwen3-Coder-480B-A35B-Instruct/summary。

### 7月22日
- 【开源】快手发布KAT-V1-40B，Kwaipilot-AutoThink 在LiveCodeBench Pro上所有开源模型中排名第一，这是一个专门设计以防止数据泄露的具有挑战性的基准测试，甚至超过了Seed和o3-mini等强大的专有系统。详细见https://modelscope.cn/models/Kwaipilot/KAT-V1-40B。
- 【闭源】谷歌发布gemini-2.5-flash-lite，这是Gemini 2.5系列的轻量版本，专注于速度快、成本低、性能高的平衡。如需了解更多有关Gemini 2.5 Flash-Lite的信息，请访问模型页面https://ai.google.dev/gemini-api/docs/models?hl=zh-cn#gemini-2.5-flash-lite。

### 7月21日
- 【开源】阿里发布Qwen3-235B-A22B-Instruct-2507，这是千问3非思考模式的更新版本，显著提升通用能力、逻辑推理和256K长文理解，在多语言知识覆盖范围大幅增加。如需了解更多信息，请访问https://modelscope.cn/models/Qwen/Qwen3-235B-A22B-Instruct-2507/summary。
<br><br>


## 7月14~7月20
### 7月17日
- 【闭源|多模态生成】谷歌发布veo-3.0-generate-preview，这是Veo的最新更新，引入了视频与音频生成功能。如需了解更多有关Veo 3的信息，请访问[模型页面](https://ai.google.dev/gemini-api/docs/models#veo-3)。
- 【闭源】谷歌提高了Imagen 4 Standard和Ultra的速率限制。更多详情请访问[速率限制页面](https://ai.google.dev/gemini-api/docs/rate-limits)。
- 【闭源】Anthropic已提高Claude Sonnet 4 的API速率限制，以便您能更从容地构建和扩展 Claude 相关应用。对于使用 1 - 4 级速率限制的客户，这些更改已立即适用于您的账户 —— 无需您采取任何操作。
- 【开源|多模态生成】HiDream-E1-1：智象未来HiDream团队在近期开源了最新迭代的图像编辑模型。支持动态分辨率，在图像质量和编辑精度方面相比上一代HiDream-E1-Full 有显著提升。[模型链接](https://www.modelscope.cn/models/HiDream-ai/HiDream-E1-1)。

### 7月16日
- 【闭源】腾讯发布turbos新版本hunyuan-turbos-20250716
- 【开源|多模态理解】Voxtral系列是Mistral AI近期发布的其首个开放式音频模型。 在 Mistral Small 3 的基础上增加了强大的音频理解能力。
  - 专用转录模式：可以在纯语音转录模式下运行，以最大化性能。默认情况下，Voxtral 会自动预测源音频的语言并相应地进行转录；
  - 长篇内容：具有 32k token的上下文长度，可处理长达 30 分钟的音频转录，或 40 分钟的理解；
  - 内置问答和摘要：支持直接通过音频提问。分析音频并生成结构化的摘要，无需单独的 ASR 和语言模型；
  - 多语言原生支持：自动语言检测和在全球最广泛使用的语言（英语、西班牙语、法语、葡萄牙语、印地语、德语、荷兰语、意大利语）中的领先性能；
  - 从语音直接调用函数：根据用户的语音意图直接触发后端功能、工作流或 API 调用；
  - 文本理解能力强：保留了其语言模型基础 Mistral Small 3.1 的文本理解能力。 
  - 模型链接：[Voxtral-Small-24B-2507](https://modelscope.cn/models/mistralai/Voxtral-Small-24B-2507)，[Voxtral-Mini-3B-2507](https://www.modelscope.cn/models/mistralai/Voxtral-Mini-3B-2507)

### 7月15日
  - 【闭源|多模态生成】智谱CogVideoX-3 视频生成模型上线新升级视频生成大模型，支持文生、图生视频，新增首尾帧生成功能，画面清晰度主观感受显著提升，主体大幅度运动自然流畅，还提升了高清现实及 3D 风格场景表现。详情见[CogVideoX-3](https://bigmodel.cn/dev/howuse/video-generation-model/CogVideoX-3)
  - 【闭源|文本】豆包发布doubao-seed-1-6-thinking-250715
  - 【闭源|文本】阿里发布qwen-turbo-2025-07-15

### 7月14日
  - 【闭源|文本】阿里发布qwen-plus-2025-07-14
  - 【闭源|向量模型】谷歌发布gemini-embedding-001，这是文本嵌入模型的稳定版本。如需了解更多，请参见[页面](https://ai.google.dev/gemini-api/docs/embeddings)。gemini-embedding-exp-03-07模型将于2025年8月14日停用。


<br><br>
## 7月7~7月13
### 7月11日
- 【开源|文本】Kimi K2：首个万亿级参数开源模型。月之暗面最新开源发布的一款具备更强代码能力、更擅长通用 Agent 任务的 MoE 架构基础模型，总参数 1T，激活参数 32B。在 SWE Bench Verified、Tau2、AceBench 等基准性能测试中，Kimi K2 均取得开源模型中的 SOTA 成绩，展现出在代码、Agent、数学推理任务上的领先能力。API价格：输入4元/百万token，输出16元/百万token。模型下载：[Kimi-K2-Instruct](https://www.modelscope.cn/models/moonshotai/Kimi-K2-Instruct)。技术博客：[Kimi-K2](https://moonshotai.github.io/Kimi-K2/)。
- 【开源|文本】Phi-4-mini-flash-reasoning：微软Phi-4 模型家族成员，一个基于合成数据构建的轻量级开放模型，专注于高质量、密集推理数据，并进一步微调以增强其高级数学推理能力，支持 64K token上下文长度。专为在内存/计算受限环境和延迟受限场景下的多步骤、逻辑密集型数学问题解决任务设计，擅长在需要深度分析思维的领域中跨步骤保持上下文、应用结构化逻辑并提供准确可靠的解决方案。模型下载：[Phi-4-mini-flash-reasoning](https://modelscope.cn/models/LLM-Research/Phi-4-mini-flash-reasoning)。
- 【闭源|文本】腾讯发布hunyuan-t1-20250711

### 7月10日
- 【闭源】Grok4：马斯克xAI发布号称宇宙最强的模型，打破多项纪录。在权威测试“Humanity’s Last Exam”（涵盖数学、科学及人文学科的 2500 道博士级难题）中，Grok 4 以 25.4% 正确率超越谷歌 Gemini 2.5 Pro（21.6%）和 OpenAI o3（21%）。马斯克称其“在所有学科表现优于博士水平”。单/多智能体协同：基础版为单智能体；Grok 4 Heavy 支持四智能体并行推理，通过协作提升复杂问题解决能力。订阅模式：标准版 30 美元/月，Grok 4 Heavy 版 300 美元/月（当前最贵 AI 订阅服务）。API价格：输入3美刀/百万token，输出15美刀/百万token。官方介绍：[grok-4](https://x.ai/news/grok-4)。[发布会链接](https://x.com/xai/status/1943158495588815072)。

### 7月9日
- 【开源】SmolLM3 ：由HuggingFace开源的一个 3B 参数的语言模型，旨在突破小型模型的界限。它支持双模式推理、6 种语言和长上下文，支持从64K扩展至128K的上下文处理，SmolLM3 是一个完全开放的模型，在 3B-4B 规模上提供了强大的性能。SmolLM3不仅公开了模型权重，还完整开源了训练数据混合、训练配置和代码。开发者可以通过Hugging Face的smollm存储库获取详细资料。
模型下载：[SmolLM3-3B](https://modelscope.cn/models/HuggingFaceTB/SmolLM3-3B)
- 【开源】Skywork-R1V3-38B：昆仑天工Skywork-R1V 系列中最新且最强大的开源多模态推理模型。基于 InternVL-38B 构建，它显著推动了多模态和跨学科智能的边界。主要通过后训练中的 RL 算法，R1V3 的推理能力得到了增强，在众多多模态推理基准测试中达到了开源的最先进（SOTA）性能。模型下载：[Skywork-R1V3-38B](https://modelscope.cn/models/Skywork/Skywork-R1V3-38B)

### 7月7日
- 【闭源】谷歌推出 Gemini API 批量模式。可将请求批量处理后异步发送。
<br><br>


## 6月30~7月6
### 7月3日
- 【闭源】Claude推出了搜索结果内容块的测试版，使 RAG 应用能够自然地进行引用。现在工具可以返回带有正确来源归属的搜索结果，并且 Claude 会自动在回复中引用这些来源，其引用质量与网络搜索相符。这消除了在自定义知识库应用中使用文档变通方法的需要。更多详情请参阅搜索结果文档。要启用此功能，请使用测试版标头 search-results-2025-06-09。

### 7月2日
- 【闭源】智谱发布GLM-4.1V-Thinking 系列视觉推理模型，GLM-4.1V-Thinking 系列是目前已知10B尺寸级别中性能最强的视觉推理模型。它在图表/视频理解、前端Coding、GUI任务等核心能力达到全面新SOTA，并引入思维链推理机制，显著提升模型在复杂场景中的回答精准度与可解释性。
- 【开源】智谱开源GLM-4.1V-9B-Thinking，基于 GLM-4-9B-0414 基座模型，推出新版VLM开源模型 GLM-4.1V-9B-Thinking ，引入思考范式，通过课程采样强化学习 RLCS（Reinforcement Learning with Curriculum Sampling）全面提升模型能力， 达到 10B 参数级别的视觉语言模型的最强性能，在18个榜单任务中持平甚至超过8倍参数量的 Qwen-2.5-VL-72B。 同步开源基座模型 GLM-4.1V-9B-Base，希望能够帮助更多研究者探索视觉语言模型的能力边界。模型下载：[GLM-4.1V-9B-Thinking](https://modelscope.cn/models/ZhipuAI/GLM-4.1V-9B-Thinking)。

### 7月1日
- 【开源】通义实验室开源ThinkSound: 多模态大型语言模型中的链式思维推理用于音频生成和编辑。尽管端到端的视频到音频生成已经取得了很大进步，但生成能够真实捕捉视觉内容微妙之处的高保真音频仍然具有挑战性。就像创意产业中的专业人士一样，这种生成需要对诸如视觉动态、声学环境和时间关系等项目进行复杂的推理。提出了 ThinkSound，这是一个新颖的框架，它利用链式思维（CoT）推理来实现逐步、交互式的音频生成和编辑。方法将过程分解为三个互补阶段：创建语义一致的声音景观的基础音效生成，通过精确的用户交互进行以对象为中心的细化，以及由自然语言指令引导的目标编辑。在每个阶段，多模态大型语言模型都会生成与上下文对齐的 CoT 推理，以指导统一的音频基础模型。此外，引入了 AudioCoT，这是一个带有结构化推理注释的综合数据集，建立了视觉内容、文本描述和声音合成之间的联系。实验表明，ThinkSound 在视频到音频生成方面达到了最先进的性能，无论是在音频指标还是 CoT 指标上，并且在分布外的电影生成音频基准测试中表现出色。[演示页面](https://ThinkSound-Project.github.io)，模型下载：[ThinkSound](https://modelscope.cn/models/iic/ThinkSound)。

### 6月30日
-【闭源】Claude宣布 Claude Opus 3 模型即将弃用。更多详情请参阅[文档](https://docs.anthropic.com/en/docs/about-claude/model-deprecations)。
<br><br>


## 6月23~6月29
### 6月29日
- 【闭源】ERNIE-4.5-Turbo-VL-Preview，图片理解、创作、翻译、代码等能力显著提升，支持128K上下文长度，首Token时延显著降低。
- 【闭源】百度文心小版本升级：ERNIE-4.5-Turbo-VL-Preview、ERNIE-4.5-Turbo-128K-Preview。
- 【开源】百度推出开源模型：ERNIE-4.5-0.3B、ERNIE-4.5-21B-A3B、多模态ERNIE-4.5-VL-28B-A3B、ERNIE-4.5-300B-A47B、多模态ERNIE-4.5-VL-424B-A47B，模型下载[ERNIE-4.5](https://modelscope.cn/collections/ERNIE-45-56f40e2777e348)。

### 6月27日
- 【开源】FLUX.1-Kontext-dev，FLUX.1 Kontext 是由 黑森林实验室（Black Forest Labs）开源的一款专业图像生成与编辑模型，专注于通过上下文感知技术实现精准的图像编辑。该模型支持文本和图像的混合输入，能够智能理解图像内容并执行对象修改、风格转换、背景替换等多种编辑任务，同时在多轮编辑中较好地保持主体一致性。其核心采用流匹配（Flow Matching）架构，结合双流与单流混合设计，提升了语义关联的精度和生成速度。Flux.1 Kontext [dev] 已正式上线ModelScope AIGC专区，支持在线免费的图像编辑。同时还支持在线界面GUI交互的模型训练，可以基于Flux.1 Kontext [dev] 底模训练LoRA模型。模型下载：[FLUX.1-Kontext-dev](https://modelscope.cn/models/black-forest-labs/FLUX.1-Kontext-dev)。
- 【开源】谷歌正式开源发布 Gemma 3n 端侧多模态模型，支持在手机、平板和笔记本电脑上本地运行，处理音频、文本、图片和视频多种数据类型。相较 此前的预览版，最新的 Gemma 3n 完整版进一步提升性能表现，支持在 2GB 内存的硬件上本地运行，重点提升了编码和推理方面的能力。本次开源提供50亿参数（E2B）和80亿参数（E4B）两种版本，实际内存占用分别相当于20亿和40亿模型。其采用MatFormer分层嵌套架构（类俄罗斯套娃设计），支持动态调节计算资源，结合Per Layer Embeddings（PLE）技术和MobileNet-v5视觉编码器，显著提升内存效率与视觉处理能力。模型强化多语言支持（140种文本语言、35种多模态理解）、数学运算、代码生成及复杂推理能力，适用于离线智能助手、实时多模态交互、本地化内容生成等场景，兼顾高性能与低功耗需求。模型下载：[gemma-3n-E2B-it](https://modelscope.cn/models/google/gemma-3n-E2B-it)。

### 6月26日
- 【闭源】阿里qwen-tts-2025-05-22，qwen-tts 模型的2025年5月22日快照版本。新增北京话、吴语和四川话三种音色。
- 【闭源】预览模型 gemini-2.5-pro-preview-05-06 和 gemini-2.5-pro-preview-03-25 现在将重定向至最新的稳定版本 gemini-2.5-pro。gemini-2.5-pro-exp-03-25 已被弃用。
- 【闭源】OpenAI推出两款全新的Deep Research API：o3-deep-research-2025-06-26和o4-mini-deep-research-2025-06-26，专为高阶分析和深度信息合成设计，可实现自动化的网页搜索、数据分析、代码执行等功能，支持多步骤研究，能生成结构化、带引用的报告。
- 【闭源】阿里通义千问推出 Qwen VLo，这是一个多模态统一理解与生成模型，引入从上到下、从左到右逐步清晰的生成过程，适用于需精细控制的长段落文字生成任务，详见[qwen-vlo](https://qwenlm.github.io/zh/blog/qwen-vlo)。未开源、未发布API，[体验地址](https://chat.qwen.ai)。
- 【开源】快手开源全新多模态大模型Keye-VL-8B-Preview，能把视频内容转化为解决方案，并且可智能选择思考模式，兼顾效率与创意。模型下载[Keye-VL-8B-Preview](https://huggingface.co/Kwai-Keye/Keye-VL-8B-Preview)。

### 6月25日
- 【开源】hunyuan-a13b 上线。适用场景：绝大部分场景，同时兼顾效果及推理性能。模型能力和特征：混元第一个混合推理模型，hunyuan-standard-256K 的升级版本，总参数80B，激活13B，默认是慢思考模式，支持通过参数或者指令进行快慢思考模式切换，慢快思考切换方式为 query 前加/ no_think；整体能力相对上一代全面提升，特别数学、科学、长文理解和 Agent 能力提升显著。模型结构：混元 MoE 结构。腾讯混元宣布开源首个混合推理 MoE 模型 Hunyuan-A13B，总参数 80B，激活参数仅 13B，效果比肩同等架构领先开源模型，且推理速度更快，性价比更高。模型下载[Hunyuan-A13B-Instruct](https://modelscope.cn/models/Tencent-Hunyuan/Hunyuan-A13B-Instruct)。
- 【闭源】百度ERNIE-4.5-Turbo-128K-Preview，模型能力全面提升，更好满足多轮长历史对话处理、长文档理解问答任务。此版本为本系列的最新版本。
- 【开源】Jina AI 正式开源发布 jina-embeddings-v4，一款全新的多模态向量模型，参数规模达到 38 亿，并首次实现了对文本与图像的同步处理。为了在各类检索任务中发挥极致性能，在模型内置了一套面向特定任务的 LoRA 适配器，专门强化了模型在处理查询-文档检索、语义匹配以及代码搜索等任务时的表现。在 MTEB、MMTEB、CoIR、LongEmbed、STS、Jina-VDR 及 ViDoRe 等多项基准测试中，jina-embeddings-v4  在多模态、多语言检索任务上均展现了顶尖性能。它尤其擅长解读富含视觉信息的内容，无论是表格、图表还是复杂的示意图，都能精准捕捉其深层语义。此外，模型还同时支持单向量和多向量表示，灵活满足各种场景需求。模型下载：[jina-embeddings-v4](https://modelscope.cn/models/jinaai/jina-embeddings-v4)。

### 6月24日
- 【闭源】谷歌发布 Imagen 4 Ultra 和标准预览模型。如需了解更多，请参见[图像生成页面](https://ai.google.dev/gemini-api/docs/image-generation)。

### 6月23日
- 【闭源】百度ERNIE-X1-Turbo-32K-Preview，相比ERNIE-X1-Turbo-32K，效果和性能更好。
- 【开源】月之暗面（MoonshotAI）开源发布了多模态模型 Kimi-VL-A3B-Thinking-2506，其凭借 28 亿激活参数、128K 上下文窗口及混合专家架构，展现出强大的视觉理解、推理及长文本、长视频处理能力。模型下载[Kimi-VL-A3B-Thinking-2506](https://modelscope.cn/models/moonshotai/Kimi-VL-A3B-Thinking-2506)。
<br><br>


## 6月16~6月22
### 6月22日
- 【闭源】MiniMax音乐模型music-1.5发布，新一代音乐生成模型，支持输入音乐灵感和歌词进行音乐生成。

### 6月19日
- 【闭源】hunyuan-t1-vision-20250619 上线。特性：混元最新版 t1-vision 多模态理解深度思考模型，支持多模态原生长思维链，相比上一代默认版本模型全面提升。
- 【闭源】hunyuan-turbos-vision-20250619 上线。特性：混元最新版 turbos-vision 视觉语言旗舰大模型，在图文理解相关的任务上，包括基于图片的实体识别、知识问答、文案创作、拍照解题等上面相比上一代默认版本模型全面提升。

### 6月18日
- 【闭源】智谱接入两个 Vidu 热门视频生成模型
  - Vidu Q1 聚焦高质量视频创作，固定输出 5 秒、24 帧、1080P 规格内容。凭借对清晰度的深度优化，画质质感大幅跃升；写实风格逼近真实场景，2D 动画画风精准保持，首尾帧转场更加丝滑，适用于影视、广告、动漫短剧等高要求创作场景。
  - Vidu 2 平衡速度、质量与成本，主攻图生视频、首尾帧功能，支持 4 秒时长下 720P分辨率输出。画面稳定可控适配电商等场景，首尾帧语义理解与多参考图一致性增强，是泛娱乐、互联网、动漫短剧、广告量产的高效工具。
- 【闭源】MiniMax视频模型MiniMax Hailuo 02正式发布，新一代视频生成模型，支持1080P高清，及10s更长视频。

### 6月17日
- 【闭源】谷歌发布 gemini-2.5-pro，这是最强大的模型的稳定版本，现已具备自适应思考功能。gemini-2.5-pro-preview-05-06 将于 2025 年 6 月 26 日重定向至 gemini-2.5-pro。
- 【闭源】谷歌发布 gemini-2.5-flash，这是首个稳定的 2.5 Flash 模型。gemini-2.5-flash-preview-04-17 将于 2025 年 7 月 15 日被弃用。
- 【闭源】谷歌发布 gemini-2.5-flash-lite-preview-06-17，这是一款低成本、高性能的 Gemini 2.5 模型。
- 【开源】Kimi-Dev-72B 是Kimi最新开源的一款大型编程语言模型，专为软件工程任务设计，通过大规模强化学习优化，能够在真实代码库中自动修复漏洞并通过测试验证，其在 SWE-bench Verified 数据集上以 60.4% 的性能刷新了开源模型的最高纪录。模型下载：[Kimi-Dev-72B](https://modelscope.cn/models/moonshotai/Kimi-Dev-72B)。

### 6月16日
- 【开源】MiniMax推理模型MiniMax-M1正式发布，全球领先：80K思维链 x 1M输入，效果比肩海外顶尖模型。MiniMax-M1 是MiniMax近期开源发布的全球首个开源的大规模混合架构推理模型，支持百万级上下文输入和最长 8 万 Token 的推理输出，总参数量 4560 亿，单次激活 459 亿 Tokens。它在长上下文理解、软件工程和工具使用等复杂任务中表现优异，性价比极高，并通过创新的强化学习算法 CISPO 实现高效训练。模型下载：[MiniMax-M1-80k](https://modelscope.cn/models/MiniMax/MiniMax-M1-80k)。
- 【开源】Lingshu系列，Lingshu-7B 是由阿里巴巴达摩院开源的一个专注于医疗领域的大型语言模型，推出7B、32B两个参数版本，在大多数医疗多模态/文本 QA 和报告生成任务中达到 SOTA 性能，能够为医学文本处理、临床辅助决策和医疗知识问答等任务提供高效支持。Lingshu-32B 在大多数多模态 QA 和报告生成任务中优于 GPT-4.1 和 Claude Sonnet 4。Lingshu 支持超过 12 种医学成像模式，包括 X 射线、CT 扫描、MRI、显微镜、超声波、组织病理学、皮肤镜检查、眼底、OCT、数字摄影、内窥镜检查和 PET。模型下载：[Lingshu-32B](https://modelscope.cn/models/DAMO_Academy/Lingshu-32B)。
<br><br>


## 6月9~6月15
### 6月15日
- 【闭源】字节跳动Doubao-Seed-1.6-thinking，在思考能力上进行了大幅强化， 对比Doubao-1.5-thinking-pro，在Coding、Math、 逻辑推理等基础能力上进一步提升。
- 【闭源】Doubao-Seed-1.6，全新多模态深度思考模型，同时支持thinking/non-thinking/auto三种思考模式， non-thinking模型对比Doubao-1.5-pro/250115大幅提升。
- 【闭源】Doubao-Seed-1.6-flash，极致推理速度的多模态深度思考模型， 同时支持文本和视觉理解，文本理解能力超过上一代lite，视觉理解比肩友商pro系列模型。

### 6月13日
- 【开源】Nanonets-OCR-s是一款强大的OCR模型，该模型基于Qwen2.5-VL-3B微调，9G显存可跑，能够通过智能内容识别和语义标记，将杂乱的文档转换为现代人工智能应用所需的干净、结构化且上下文丰富的 Markdown 格式。它的功能远超传统的文本提取，是目前图像转 Markdown 领域的SoTA模型。模型下载：[Nanonets-OCR-s](https://modelscope.cn/models/nanonets/Nanonets-OCR-s)。

### 6月11日
- 【开源】Magistral-Small-2506是基于Mistral Small 3.1（2503版本）的升级模型，通过融合Magistral Medium轨迹的监督微调（SFT）与强化学习（RL）训练，显著增强推理能力。这款高效的小型推理模型参数量达240亿，量化后可在单张RTX 4090显卡或32GB内存的MacBook本地部署。Magistral-Small-2506具备长推理链能力，支持英语、法语、中文等数十种语言，采用Apache 2.0开源许可（允许商业及非商业使用）。其128k上下文窗口实际建议设为40k，超过此范围性能可能下降。模型下载：[Magistral-Small-2506](https://modelscope.cn/models/mistralai/Magistral-Small-2506)。

### 6月10日
- 【闭源】OpenAI推出o3-pro，如同 o1-pro 一样，o3-pro 是最智能的模型 o3 的一个版本，专为长时间思考并提供最可靠的回答而设计。自 o1-pro 推出以来，用户一直青睐该模型在数学、科学和编程等领域的表现，而 o3-pro 在学术评估中也继续在这些领域表现出色。和 o3 一样，o3-pro 可以使用各种工具，使 ChatGPT 更加实用——它可以搜索网络、分析文件、对视觉输入进行推理、使用 Python、利用记忆个性化回答等等。

### 6月9日
- 【开源】MonkeyOCR是由华中科技大学联合金山办公推出的一款文档解析模型，具备高精度和强泛化能力。该模型支持多语言、多场景的文字检测与识别，适用于文档数字化、内容审核、信息提取等多种应用场合。与传统方法相比，MonkeyOCR在处理复杂文档时，平均性能提升5.1%，在公式和表格解析上分别提升15%、8.6%。模型下载：[MonkeyOCR](https://modelscope.cn/models/l1731396519/MonkeyOCR)。


<br><br>
## 6月2~6月8
### 6月7日
- 【闭源】OpenAI高级语音模式更新，为付费用户在 ChatGPT 中升级了高级语音模式，显著提升了语调和自然度，让对话更加流畅自然。

### 6月6日
- 【闭源】OpenAI o4-mini更新，撤销了不到一周前部署的 o4-mini 快照版本，该版本原本旨在延长模型回答的长度，但自动化监控工具发现内容标记有所增加。
- 【闭源】hunyuan-translation-lite模型版本更新。模型能力和特征：混元翻译专项模型，基于混元2B-Dense模型进行翻译能力专项优化，通过迭代高质量多语言SFT数据，强化多语种翻译能力。支持简体中文、繁体中文、粤语、印尼语、英语、日语、法语、葡萄牙语、西班牙语、土耳其语、俄语、阿拉伯语、韩语、意大利语、德语、越南语、马来语、印尼语等18种语言互译。模型结构：混元 Dense 结构。
- 【开源】dots.llm1 模型是小红书Hi lab团队（Humane Intelligence Lab）推出的一个大规模的 MoE 模型，从总共 142B 参数中激活了 14B 参数，性能与当前最先进的开源模型相当。 通过rednote-hilab研究团队精心设计和高效的数据处理流水线，dots.llm1 在没有合成数据的情况下，在高质量语料库上预训练后，达到了与 Qwen2.5-72B 相当的性能。为了进一步促进研究，研究团队开源了整个训练过程中的中间训练Checkpoint，并提供了对大型语言模型学习动态的宝贵见解。模型下载：[dots.llm1.inst](https://modelscope.cn/models/rednote-hilab/dots.llm1.inst)。

### 6月5日
- 【闭源】谷歌发布 gemini-2.5-pro-preview-06-05，这是最强大的模型的新版本，现已具备自适应思考功能。如需了解更多，请参见 Gemini 2.5 Pro 预览版和思考。gemini-2.5-pro-preview-05-06 将于 2025 年 6 月 26 日重定向至 gemini-2.5-pro。
- 【开源】面壁智能重磅推出MiniCPM 4.0 ——一个极致高效的端侧大模型，通过其 CPM.cu 自研推理框架，可实现220倍极致的速度提升，5 倍常规提速。本次在开源社区核心推出 8B 和 0.5B 两个参数规模的版本，均在同级别模型对比中实现了最佳性能。MiniCPM4系列通过系统性技术创新实现端侧大模型极致推理效率：采用InfLLM v2可训练稀疏注意力架构，在128K长文本处理中将词元关联计算量压缩至不足5%；结合BitCPM三值量化技术实现模型位宽90%压缩，配合FP8低精度计算与多词元预测策略显著降低训练成本；依托UltraClean数据清洗和UltraChat v2合成技术构建高质量多维训练集；推理端集成CPM.cu高效CUDA框架，融合稀疏注意力、模型量化与投机采样技术，并通过ArkInfer跨平台系统实现灵活部署。模型下载：[MiniCPM4-0.5B](https://modelscope.cn/models/OpenBMB/MiniCPM4-0.5B)。

### 6月4日
- 【闭源】腾讯混元hunyuan-turbos-20250604 上线。能力和特征：预训练底座升级，写作、阅读理解能力提升，较大幅度提升代码和理科能力，复杂指令遵循等持续提升。
- 【闭源】阿里发布text-embedding-v4，text-embedding-v4为text-embedding-v3的升级版模型，属于Qwen3-Embedding系列。相较于上一版模型，新版模型涵盖了更多自然语言以及多种编程语言，并新增2048及1536向量维度的选择。
- 【开源】阿里巴巴通义实验室开源Qwen3-Embedding系列模型, Qwen模型家族的新成员。该系列模型专为文本表征、检索与排序任务设计，基于Qwen3基础模型进行训练，充分继承了Qwen3在多语言文本理解能力方面的优势。基于Qwen3基础模型，Embedding模型和Reranker模型分别采用了双塔结构和单塔结构的设计。通过LoRA微调，最大限度地保留并继承了基础模型的文本理解能力。模型下载：[Qwen3-Embedding-8B](https://modelscope.cn/models/Qwen/Qwen3-Embedding-8B)。

### 6月3日
- 【闭源】阿里发布qvq-max-2025-05-15，视觉推理模型。较上一个版本，增强了在数学、编程、视觉分析、创作以及通用任务方面的能力。
- 【闭源】阿里发布qvq-plus-2025-05-15，视觉推理模型。支持视觉输入及思维链输出，继qvq-max模型后推出的plus版本，相较于qvq-max模型，qvq-plus系列模型推理速度更快，效果和成本更均衡。
- 【闭源】商汤发布最新版本日日新-语音大模型-语音合成（音色融合），日日新语音合成（音色融合）大模型基于文本到语音（Text-to-Speech, TTS）的同步语音合成功能，单次请求支持最大文本长度为 10000 字符，适用于短句生成、语音对话、在线社交等多种场景。








