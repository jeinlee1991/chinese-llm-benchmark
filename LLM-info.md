# ä¸­æ–‡å¤§æ¨¡å‹æ±‡æ€»
ğŸ“å¤§æ¨¡å‹åŸºæœ¬ä¿¡æ¯
ä»·æ ¼å•ä½ï¼šå…ƒ/1m tokensï¼Œå³å…ƒæ¯ç™¾ä¸‡token    

| ç±»åˆ« | å¤§æ¨¡å‹                    | ä»·æ ¼/ä¸‹è½½              | æœºæ„        |
|----|------------------------|--------------------|-----------|
| å•†ç”¨ | qwen-long              | è¾“å…¥ï¼š0.5ï¼Œè¾“å‡ºï¼š 2       | é˜¿é‡Œ        |
| å•†ç”¨ | qwen-turbo             | è¾“å…¥ï¼š2ï¼Œè¾“å‡ºï¼š6          | é˜¿é‡Œ        |
| å•†ç”¨ | qwen-plus              | è¾“å…¥ï¼š4ï¼Œè¾“å‡ºï¼š12         | é˜¿é‡Œ        |
| å•†ç”¨ | qwen-max               | è¾“å…¥ï¼š40ï¼Œè¾“å‡ºï¼š120       | é˜¿é‡Œ        |
| å•†ç”¨ | gpt-4o                 | è¾“å…¥ï¼š36.2ï¼Œè¾“å‡ºï¼š108.6   | openAI    |
| å•†ç”¨ | gpt-4-turbo            | è¾“å…¥ï¼š72.4ï¼Œè¾“å‡ºï¼š217.2   | openAI    |
| å•†ç”¨ | gpt-4                  | è¾“å…¥ï¼š217.2ï¼Œè¾“å‡ºï¼š 434.4 | openAI    |
| å•†ç”¨ | gpt-3.5-turbo          | è¾“å…¥ï¼š3.6ï¼Œè¾“å‡ºï¼š10.9     | openAI    |
| å•†ç”¨ | Gemini 1.5 pro         | è¾“å…¥ï¼š25.3ï¼Œè¾“å‡ºï¼š 76     | è°·æ­Œ        |
| å•†ç”¨ | Gemini 1.5 Flash       | è¾“å…¥ï¼š2.5ï¼Œè¾“å‡ºï¼š7.6      | è°·æ­Œ        |
| å•†ç”¨ | Gemini 1.0 pro         | è¾“å…¥ï¼š3.6ï¼Œè¾“å‡ºï¼š 10.9    | è°·æ­Œ        |
| å•†ç”¨ | Claude 3.5 Sonnet      | è¾“å…¥ï¼š21.7ï¼Œè¾“å‡ºï¼š108.6   | anthropic |
| å•†ç”¨ | claude 3 opus          | è¾“å…¥ï¼š108.6ï¼Œè¾“å‡ºï¼š543    | anthropic |
| å•†ç”¨ | claude 3 sonnet        | è¾“å…¥ï¼š21.7ï¼Œè¾“å‡ºï¼š 108.6  | anthropic |
| å•†ç”¨ | Claude 3 Haiku         | è¾“å…¥ï¼š1.8ï¼Œè¾“å‡ºï¼š9.1      | anthropic |
| å•†ç”¨ | yi-large               | è¾“å…¥ï¼š20ï¼Œè¾“å‡ºï¼š20        | é›¶ä¸€ä¸‡ç‰©      |
| å•†ç”¨ | yi-large-turbo         | è¾“å…¥ï¼š12ï¼Œè¾“å‡ºï¼š12        | é›¶ä¸€ä¸‡ç‰©      |
| å•†ç”¨ | yi-large-rag           | è¾“å…¥ï¼š25ï¼Œè¾“å‡ºï¼š 25       | é›¶ä¸€ä¸‡ç‰©      |
| å•†ç”¨ | yi-medium              | è¾“å…¥ï¼š2.5ï¼Œè¾“å‡ºï¼š2.5      | é›¶ä¸€ä¸‡ç‰©      |
| å•†ç”¨ | yi-medium-200k         | è¾“å…¥ï¼š12ï¼Œè¾“å‡ºï¼š12        | é›¶ä¸€ä¸‡ç‰©      |
| å•†ç”¨ | yi-spark               | è¾“å…¥ï¼š1ï¼Œè¾“å‡ºï¼š1          | é›¶ä¸€ä¸‡ç‰©      |
| å•†ç”¨ | GLM-4 / GLM-4-AllTools | è¾“å…¥ï¼š100ï¼Œè¾“å‡ºï¼š100      | æ™ºè°±        |     
| å•†ç”¨ | GLM-4V                 | è¾“å…¥ï¼š50ï¼Œè¾“å‡ºï¼š50        | æ™ºè°±        |     
| å•†ç”¨ | GLM-4-AirX             | è¾“å…¥ï¼š10ï¼Œè¾“å‡ºï¼š 10       | æ™ºè°±        |     
| å•†ç”¨ | GLM-4-Air              | è¾“å…¥ï¼š1ï¼Œè¾“å‡ºï¼š 1         | æ™ºè°±        |     
| å•†ç”¨ | GLM-4-Flash            | è¾“å…¥ï¼š0.1ï¼Œè¾“å‡ºï¼š0.1      | æ™ºè°±        |     
| å•†ç”¨ | abab6.5                | è¾“å…¥ï¼š30ï¼Œè¾“å‡ºï¼š30        | minimax   |     
| å•†ç”¨ | abab6.5s               | è¾“å…¥ï¼š10ï¼Œè¾“å‡ºï¼š10        | minimax   |     
| å•†ç”¨ | abab6.5t / abab6.5g    | è¾“å…¥ï¼š5ï¼Œè¾“å‡ºï¼š5          | minimax   |     
| å•†ç”¨ | abab5.5                | è¾“å…¥ï¼š15ï¼Œè¾“å‡ºï¼š 15       | minimax   |     
| å•†ç”¨ | abab5.5s               | è¾“å…¥ï¼š5ï¼Œè¾“å‡ºï¼š 5         | minimax   |     
| å•†ç”¨ | deepseek-v2            | è¾“å…¥ï¼š1ï¼Œè¾“å‡ºï¼š2          | æ·±åº¦æ±‚ç´¢      |     
| å•†ç”¨ | ERNIE 4.0              | è¾“å…¥ï¼š40ï¼Œè¾“å‡ºï¼š120       | ç™¾åº¦        |     
| å•†ç”¨ | ERNIE 4.0 Turbo        | è¾“å…¥ï¼š30ï¼Œè¾“å‡ºï¼š60        | ç™¾åº¦        |     
| å•†ç”¨ | ERNIE 3.5              | è¾“å…¥ï¼š4ï¼Œè¾“å‡ºï¼š12         | ç™¾åº¦        |     
| å•†ç”¨ | ERNIE Speed/Lite/Tiny  | å…è´¹                 | ç™¾åº¦        |     
| å•†ç”¨ | moonshot-v1-8k         | è¾“å…¥ï¼š12ï¼Œè¾“å‡ºï¼š12        | æœˆä¹‹æš—é¢      |     
| å•†ç”¨ | moonshot-v1-32k        | è¾“å…¥ï¼š24ï¼Œè¾“å‡ºï¼š24        | æœˆä¹‹æš—é¢      |     
| å•†ç”¨ | moonshot-v1-128k       | è¾“å…¥ï¼š60ï¼Œè¾“å‡ºï¼š60        | æœˆä¹‹æš—é¢      |     
| å•†ç”¨ | spark 4 ultra          | è¾“å…¥ï¼š100ï¼Œè¾“å‡ºï¼š100      | è®¯é£æ˜Ÿç«      |     
| å•†ç”¨ | spark max/pro          | è¾“å…¥ï¼š30ï¼Œè¾“å‡ºï¼š30        | è®¯é£æ˜Ÿç«      |     
| å•†ç”¨ | spark lite             | å…è´¹                 | è®¯é£æ˜Ÿç«      |     
| å•†ç”¨ | Baichuan4              | è¾“å…¥ï¼š100ï¼Œè¾“å‡ºï¼š100      | ç™¾å·æ™ºèƒ½      |     
| å•†ç”¨ | Baichuan3-Turbo        | è¾“å…¥ï¼š12ï¼Œè¾“å‡ºï¼š12        | ç™¾å·æ™ºèƒ½      |     
| å•†ç”¨ | Baichuan3-Turbo-128k   | è¾“å…¥ï¼š24ï¼Œè¾“å‡ºï¼š24        | ç™¾å·æ™ºèƒ½      |     
| å•†ç”¨ | Baichuan2-Turbo        | è¾“å…¥ï¼š8ï¼Œè¾“å‡ºï¼š8          | ç™¾å·æ™ºèƒ½      |     
| å•†ç”¨ | Doubao-pro-128k        | è¾“å…¥ï¼š5ï¼Œè¾“å‡ºï¼š9          | å­—èŠ‚è·³åŠ¨      |     
| å•†ç”¨ | Doubao-pro-4k/32k      | è¾“å…¥ï¼š0.8ï¼Œè¾“å‡ºï¼š2        | å­—èŠ‚è·³åŠ¨      |     
| å•†ç”¨ | Doubao-lite-128k       | è¾“å…¥ï¼š0.8ï¼Œè¾“å‡ºï¼š1        | å­—èŠ‚è·³åŠ¨      |     
| å•†ç”¨ | Doubao-lite-4k/32k     | è¾“å…¥ï¼š0.3ï¼Œè¾“å‡ºï¼š0.6      | å­—èŠ‚è·³åŠ¨      |     
| å•†ç”¨ |                        | è¾“å…¥ï¼šï¼Œè¾“å‡ºï¼š            |           |     
<br><br>     
      


| å¤§æ¨¡å‹                                                                                     | æœºæ„             | ç±»åˆ«    | å¤‡æ³¨                                                                                                                                                                                                                                                                                                                                                                                                                                             |
|-----------------------------------------------------------------------------------------|----------------|-------|------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| [chatgpt-3.5](https://chat.openai.com/)                                                 | openai         | å•†ç”¨    | é£é¡ä¸–ç•Œçš„AIäº§å“ï¼ŒAPIä¸ºgpt3.5-turbo                                                                                                                                                                                                                                                                                                                                                                                                                     |
| [gpt4](https://chat.openai.com/)                                                        | openai         | å•†ç”¨    | å½“å‰ä¸–ç•Œæœ€å¼ºAI                                                                                                                                                                                                                                                                                                                                                                                                                                       |
| [new-bing](https://www.bing.com/)                                                       | å¾®è½¯             | å•†ç”¨  |bingæœç´¢ç”¨çš„èŠå¤©æ¨¡å‹ï¼ŒåŸºäºGPT4|
| [æ–‡å¿ƒä¸€è¨€](https://yiyan.baidu.com/)                                                        | ç™¾åº¦             | å•†ç”¨    | ç™¾åº¦å…¨æ–°ä¸€ä»£çŸ¥è¯†å¢å¼ºå¤§è¯­è¨€æ¨¡å‹ï¼Œæ–‡å¿ƒå¤§æ¨¡å‹å®¶æ—çš„æ–°æˆå‘˜ï¼Œèƒ½å¤Ÿä¸äººå¯¹è¯äº’åŠ¨ï¼Œå›ç­”é—®é¢˜ï¼ŒååŠ©åˆ›ä½œï¼Œé«˜æ•ˆä¾¿æ·åœ°å¸®åŠ©äººä»¬è·å–ä¿¡æ¯ã€çŸ¥è¯†å’Œçµæ„Ÿã€‚                                                                                                                                                                                                                                                                                                                                                                                                                                                        |
| [chatglmå®˜æ–¹](https://chatglm.cn/)                                                        | æ™ºè°±AI           | å•†ç”¨    | ä¸€ä¸ªå…·æœ‰é—®ç­”ã€å¤šè½®å¯¹è¯å’Œä»£ç ç”ŸæˆåŠŸèƒ½çš„ä¸­è‹±åŒè¯­æ¨¡å‹ï¼ŒåŸºäºåƒäº¿åŸºåº§ GLM-130B å¼€å‘ï¼Œé€šè¿‡ä»£ç é¢„è®­ç»ƒã€æœ‰ç›‘ç£å¾®è°ƒç­‰æŠ€æœ¯æå‡å„é¡¹èƒ½åŠ›                                                                                                                                                                                                                                                                                                                                                                                                                                                        |
| [è®¯é£æ˜Ÿç«](https://xinghuo.xfyun.cn/desk)                                                   | ç§‘å¤§è®¯é£           | å•†ç”¨    | å…·æœ‰æ–‡æœ¬ç”Ÿæˆã€è¯­è¨€ç†è§£ã€çŸ¥è¯†é—®ç­”ã€é€»è¾‘æ¨ç†ã€æ•°å­¦èƒ½åŠ›ã€ä»£ç èƒ½åŠ›ã€å¤šæ¨¡æ€èƒ½åŠ› 7 å¤§æ ¸å¿ƒèƒ½åŠ›ã€‚è¯¥å¤§æ¨¡å‹ç›®å‰å·²åœ¨æ•™è‚²ã€åŠå…¬ã€è½¦è½½ã€æ•°å­—å‘˜å·¥ç­‰å¤šä¸ªè¡Œä¸šå’Œäº§å“ä¸­è½åœ°ã€‚                                                                                                                                                                                                                                                                                                                                                                                                                                            |
| [360æ™ºè„‘](https://ai.360.cn/)                                                             | å¥‡è™360          | å•†ç”¨    | -                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          |
| [é˜¿é‡Œé€šä¹‰åƒé—®](https://tongyi.aliyun.com/)                                                    | é˜¿é‡Œå·´å·´           | å•†ç”¨    | é€šä¹‰åƒé—®æ”¯æŒå¤šè½®å¯¹è¯ï¼Œå¯è¿›è¡Œæ–‡æ¡ˆåˆ›ä½œã€é€»è¾‘æ¨ç†ï¼Œæ”¯æŒå¤šç§è¯­è¨€ã€‚                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            |
| [senseChat](https://chat.sensetime.com/)                                                | å•†æ±¤             |å•†ç”¨|å•†æ±¤æ¨å‡ºçš„èŠå¤©æ¨¡å‹|
| [minimax](https://api.minimax.chat/)                                                    | minimax        | å•†ç”¨    | Glow appèƒŒåå¤§æ¨¡å‹                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |
| [tigerbot-7bå®˜ç½‘](https://www.tigerbot.com/)                                              | è™åšç§‘æŠ€           | å•†ç”¨/å¼€æº | TigerBot æ˜¯ä¸€ä¸ªå¤šè¯­è¨€å¤šä»»åŠ¡çš„å¤§è§„æ¨¡è¯­è¨€æ¨¡å‹(LLM)ï¼ŒåŸºäºbloomæ¨¡å‹ç»“æ„ã€‚è¯¥æ¨¡å‹ä¹Ÿæœ‰å¼€æºç‰ˆæœ¬ã€‚                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |
| [chatglm-6b](https://github.com/THUDM/ChatGLM-6B)                                       | æ¸…åå¤§å­¦&æ™ºè°±AI      | å¼€æº    | ChatGLM-6B æ˜¯ä¸€ä¸ªå¼€æºçš„ã€æ”¯æŒä¸­è‹±åŒè¯­çš„å¯¹è¯è¯­è¨€æ¨¡å‹ï¼ŒåŸºäº General Language Model (GLM) æ¶æ„ï¼Œå…·æœ‰ 62 äº¿å‚æ•°ã€‚ç»“åˆæ¨¡å‹é‡åŒ–æŠ€æœ¯ï¼Œç”¨æˆ·å¯ä»¥åœ¨æ¶ˆè´¹çº§çš„æ˜¾å¡ä¸Šè¿›è¡Œæœ¬åœ°éƒ¨ç½²ï¼ˆINT4 é‡åŒ–çº§åˆ«ä¸‹æœ€ä½åªéœ€ 6GB æ˜¾å­˜ï¼‰ã€‚ ChatGLM-6B ä½¿ç”¨äº†å’Œ ChatGPT ç›¸ä¼¼çš„æŠ€æœ¯ï¼Œé’ˆå¯¹ä¸­æ–‡é—®ç­”å’Œå¯¹è¯è¿›è¡Œäº†ä¼˜åŒ–ã€‚ç»è¿‡çº¦ 1T æ ‡è¯†ç¬¦çš„ä¸­è‹±åŒè¯­è®­ç»ƒï¼Œè¾…ä»¥ç›‘ç£å¾®è°ƒã€åé¦ˆè‡ªåŠ©ã€äººç±»åé¦ˆå¼ºåŒ–å­¦ä¹ ç­‰æŠ€æœ¯çš„åŠ æŒï¼Œ62 äº¿å‚æ•°çš„ ChatGLM-6B å·²ç»èƒ½ç”Ÿæˆç›¸å½“ç¬¦åˆäººç±»åå¥½çš„å›ç­”                                                                                                                                                                                                                                                             |
| [belle-llama-7b-2m](https://github.com/LianjiaTech/BELLE)                               | é“¾å®¶ç§‘æŠ€           | å¼€æº    | based on LLAMA 7B and finetuned with 2M Chinese data combined with 50,000 pieces of English data from the open source Stanford-Alpaca, resulting in good Chinese instruction understanding and response generation capabilities.                                                                                                                                                                                                                                                                                           |
| [BELLE-on-Open-Datasets](https://github.com/LianjiaTech/BELLE)                          | é“¾å®¶ç§‘æŠ€           | å¼€æº    | Extending the vocabulary with additional 50K tokens specific for Chinese and further pretraining these word embeddings on Chinese corpus. Full-parameter finetuning the model with  instruction-following open datasets: alpaca, sharegpt, belle-3.5m.                                                                                                                                                                                                                                                                     |
| [belle-llama-13b-2m](https://github.com/LianjiaTech/BELLE)                              | é“¾å®¶ç§‘æŠ€           | å¼€æº    | based on LLAMA 13B and finetuned with 2M Chinese data combined with 50,000 pieces of English data from the open source Stanford-Alpaca.                                                                                                                                                                                                                                                                                                                                                                                    |
| [belle-llama-13b-ext](https://github.com/LianjiaTech/BELLE)                             | é“¾å®¶ç§‘æŠ€           | å¼€æº    | Extending the vocabulary with additional 50K tokens specific for Chinese and further pretraining these word embeddings on Chinese corpus. Full-parameter finetuning the model with 4M high-quality instruction-following examples.                                                                                                                                                                                                                                                                                         |
| [BELLE-Llama2-13B-chat-0.4M](https://huggingface.co/BELLE-2/BELLE-Llama2-13B-chat-0.4M) |é“¾å®¶ç§‘æŠ€|å¼€æº |This model is obtained by fine-tuning the complete parameters using 0.4M Chinese instruction data on the original Llama2-13B-chat. |
| [Ziya-LLaMA-13B-v1](https://mp.weixin.qq.com/s/IeXgq8blGoeVbpIlAUCAjA)                  | IDEAç ”ç©¶é™¢        | å¼€æº    | ä»LLaMA-13Bå¼€å§‹é‡æ–°æ„å»ºä¸­æ–‡è¯è¡¨ï¼Œè¿›è¡Œåƒäº¿tokené‡çº§çš„å·²çŸ¥çš„æœ€å¤§è§„æ¨¡ç»§ç»­é¢„è®­ç»ƒï¼Œä½¿æ¨¡å‹å…·å¤‡åŸç”Ÿä¸­æ–‡èƒ½åŠ›ã€‚å†ç»è¿‡500ä¸‡æ¡å¤šä»»åŠ¡æ ·æœ¬çš„æœ‰ç›‘ç£å¾®è°ƒ(SFT)å’Œç»¼åˆäººç±»åé¦ˆè®­ç»ƒï¼ˆRM+PPO+HFFT+COHFT+RBRS)ï¼Œè¿›ä¸€æ­¥æ¿€å‘å’ŒåŠ å¼ºå„ç§AIä»»åŠ¡èƒ½åŠ›ã€‚                                                                                                                                                                                                                                                                                                                                                                                      |
| [Ziya-LLaMA-13B-v1.1](https://huggingface.co/IDEA-CCNL/Ziya-LLaMA-13B-v1.1)             | IDEAç ”ç©¶é™¢        | å¼€æº    | å¯¹Ziya-LLaMA-13B-v1æ¨¡å‹è¿›è¡Œç»§ç»­ä¼˜åŒ–ï¼Œé€šè¿‡è°ƒæ•´å¾®è°ƒæ•°æ®çš„æ¯”ä¾‹å’Œé‡‡ç”¨æ›´ä¼˜çš„å¼ºåŒ–å­¦ä¹ ç­–ç•¥ï¼Œæœ¬ç‰ˆæœ¬åœ¨é—®ç­”å‡†ç¡®æ€§ã€æ•°å­¦èƒ½åŠ›ä»¥åŠå®‰å…¨æ€§ç­‰æ–¹é¢å¾—åˆ°äº†æå‡                                                                                                                                                                                                                                                                                                                                                                                                                                             |
| [guanaco-7b](https://huggingface.co/JosephusCheung/Guanaco)                             | JosephusCheung | å¼€æº    | Guanaco is an advanced instruction-following language model built on Meta's LLaMA 7B model. Expanding upon the initial 52K dataset from the Alpaca model, an additional 534K+ entries have been incorporated, covering English, Simplified Chinese, Traditional Chinese (Taiwan), Traditional Chinese (Hong Kong), Japanese, Deutsch, and various linguistic and grammatical tasks. This wealth of data enables Guanaco to perform exceptionally well in multilingual environments.                                        |
| [phoenix-inst-chat-7b](https://github.com/FreedomIntelligence/LLMZoo)                   | é¦™æ¸¯ä¸­æ–‡å¤§å­¦         | å¼€æº    | åŸºäºBLOOMZ-7b1-mtï¼Œç”¨Instruction + Conversationæ•°æ®å¾®è°ƒï¼Œå…·ä½“æ•°æ®è§[phoenix-sft-data-v1](https://huggingface.co/datasets/FreedomIntelligence/phoenix-sft-data-v1)                                                                                                                                                                                                                                                                                                                                                                        |
| [linly-chatflow-13b](https://github.com/CVI-SZU/Linly)                                  | æ·±åœ³å¤§å­¦           | å¼€æº    | åŸºäºllama-13bï¼Œç”¨5M æŒ‡ä»¤æ•°æ®å¾®è°ƒ                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |
| [Linly-Chinese-LLaMA2-13B](https://huggingface.co/Linly-AI/Chinese-LLaMA-2-13B-hf)      |æ·±åœ³å¤§å­¦|å¼€æº|Linly-Chinese-LLaMA2 åŸºäº LLaMA2è¿›è¡Œä¸­æ–‡åŒ–è®­ç»ƒï¼Œä½¿ç”¨è¯¾ç¨‹å­¦ä¹ æ–¹æ³•è·¨è¯­è¨€è¿ç§»ï¼Œè¯è¡¨é’ˆå¯¹ä¸­æ–‡é‡æ–°è®¾è®¡ï¼Œæ•°æ®åˆ†å¸ƒæ›´å‡è¡¡ï¼Œæ”¶æ•›æ›´ç¨³å®šã€‚|
| [MOSS-003-SFT](https://github.com/OpenLMLab/MOSS)                                       | å¤æ—¦å¤§å­¦           | å¼€æº    | MOSSæ˜¯ä¸€ä¸ªæ”¯æŒä¸­è‹±åŒè¯­å’Œå¤šç§æ’ä»¶çš„å¼€æºå¯¹è¯è¯­è¨€æ¨¡å‹ï¼Œmoss-moonç³»åˆ—æ¨¡å‹å…·æœ‰160äº¿å‚æ•°ï¼Œåœ¨FP16ç²¾åº¦ä¸‹å¯åœ¨å•å¼ A100/A800æˆ–ä¸¤å¼ 3090æ˜¾å¡è¿è¡Œï¼Œåœ¨INT4/8ç²¾åº¦ä¸‹å¯åœ¨å•å¼ 3090æ˜¾å¡è¿è¡Œã€‚MOSSåŸºåº§è¯­è¨€æ¨¡å‹åœ¨çº¦ä¸ƒåƒäº¿ä¸­è‹±æ–‡ä»¥åŠä»£ç å•è¯ä¸Šé¢„è®­ç»ƒå¾—åˆ°ï¼Œåç»­ç»è¿‡å¯¹è¯æŒ‡ä»¤å¾®è°ƒã€æ’ä»¶å¢å¼ºå­¦ä¹ å’Œäººç±»åå¥½è®­ç»ƒå…·å¤‡å¤šè½®å¯¹è¯èƒ½åŠ›åŠä½¿ç”¨å¤šç§æ’ä»¶çš„èƒ½åŠ›ã€‚                                                                                                                                                                                                                                                                                                                                       |
| [AquilaChat-7B](https://github.com/FlagAI-Open/FlagAI/blob/master/examples/Aquila/README.md) | æ™ºæºç ”ç©¶é™¢          | å¼€æº    | æ‚Ÿé“Â·å¤©é¹°ï¼ˆAquilaï¼‰ è¯­è¨€å¤§æ¨¡å‹æ˜¯é¦–ä¸ªå…·å¤‡ä¸­è‹±åŒè¯­çŸ¥è¯†ã€æ”¯æŒå•†ç”¨è®¸å¯åè®®ã€å›½å†…æ•°æ®åˆè§„éœ€æ±‚çš„å¼€æºè¯­è¨€å¤§æ¨¡å‹ã€‚AquilaChat å¯¹è¯æ¨¡å‹æ”¯æŒæµç•…çš„æ–‡æœ¬å¯¹è¯åŠå¤šç§è¯­è¨€ç±»ç”Ÿæˆä»»åŠ¡ï¼Œé€šè¿‡å®šä¹‰å¯æ‰©å±•çš„ç‰¹æ®ŠæŒ‡ä»¤è§„èŒƒï¼Œå®ç° AquilaChatå¯¹å…¶å®ƒæ¨¡å‹å’Œå·¥å…·çš„è°ƒç”¨ï¼Œä¸”æ˜“äºæ‰©å±•ã€‚                                                                                                                                                                                                                                                                                                                                                                                 |
| [tulu-30b](https://github.com/allenai/open-instruct)                                    | allenai        | å¼€æº    | We explore instruction-tuning popular base models on publicly available datasets. As part of this work we introduce TÃ¼lu, a suite of LLaMa models fully-finetuned on a strong mix of datasets!                                                                                                                                                                                                                                                                                                                             |
| [chatglm2-6b](https://github.com/THUDM/ChatGLM2-6B)                                     | æ¸…åå¤§å­¦&æ™ºè°±AI      | å¼€æº    | ChatGLM2-6B æ˜¯ChatGLM-6B çš„ç¬¬äºŒä»£ç‰ˆæœ¬ï¼Œæ›´å¼ºå¤§çš„æ€§èƒ½ï¼Œä¸Šä¸‹æ–‡é•¿åº¦ä»2K æ‰©å±•åˆ°äº† 32Kï¼Œæ¨ç†é€Ÿåº¦ç›¸æ¯”åˆä»£æå‡äº† 42%ï¼Œå…è®¸å•†ä¸šä½¿ç”¨ã€‚                                                                                                                                                                                                                                                                                                                                                                                                                                            |
| [Baichuan-13B-Chat](https://github.com/baichuan-inc/Baichuan-13B)                       | ç™¾å·æ™ºèƒ½           | å¼€æº    | Baichuan-13B æ˜¯ç”±ç™¾å·æ™ºèƒ½ç»§ Baichuan-7B ä¹‹åå¼€å‘çš„åŒ…å« 130 äº¿å‚æ•°çš„å¼€æºå¯å•†ç”¨çš„å¤§è§„æ¨¡è¯­è¨€æ¨¡å‹ï¼Œåœ¨æƒå¨çš„ä¸­æ–‡å’Œè‹±æ–‡ benchmark ä¸Šå‡å–å¾—åŒå°ºå¯¸æœ€å¥½çš„æ•ˆæœã€‚                                                                                                                                                                                                                                                                                                                                                                                                                           |
| [vicuna-33b](https://github.com/lm-sys/FastChat)                                        | UCä¼¯å…‹åˆ©          | å¼€æº    | Vicuna is a chat assistant trained by fine-tuning LLaMA on user-shared conversations collected from ShareGPT.                                                                                                                                                                                                                                                                                                                                                                                                              |
| [wizardlm-13b](https://github.com/nlpxucan/WizardLM)                                    | å¾®è½¯             | å¼€æº    | WizardLM: An Instruction-following LLM Using Evol-Instruct                                                                                                                                                                                                                                                                                                                                                                                                                                                                 |
| [InternLM-Chat-7B](https://github.com/InternLM/InternLM/tree/main)                      | ä¸Šæµ·äººå·¥æ™ºèƒ½å®éªŒå®¤      | å¼€æº    | ä½¿ç”¨ä¸Šä¸‡äº¿é«˜è´¨é‡è¯­æ–™ï¼Œå»ºç«‹æ¨¡å‹è¶…å¼ºçŸ¥è¯†ä½“ç³»ï¼›æ”¯æŒ8kè¯­å¢ƒçª—å£é•¿åº¦ï¼Œå®ç°æ›´é•¿è¾“å…¥ä¸æ›´å¼ºæ¨ç†ä½“éªŒï¼›é€šç”¨å·¥å…·è°ƒç”¨èƒ½åŠ›ï¼Œæ”¯æŒç”¨æˆ·çµæ´»è‡ªåŠ©æ­å»ºæµç¨‹ã€‚                                                                                                                                                                                                                                                                                                                                                                                                                                                      |
| [Llama-2-70b-chat](https://github.com/facebookresearch/llama)                           | meta           | å¼€æº    | Meta developed and publicly released the Llama 2 family of large language models (LLMs), a collection of pretrained and fine-tuned generative text models ranging in scale from 7 billion to 70 billion parameters. Our fine-tuned LLMs, called Llama-2-Chat, are optimized for dialogue use cases. Llama-2-Chat models outperform open-source chat models on most benchmarks we tested, and in our human evaluations for helpfulness and safety, are on par with some popular closed-source models like ChatGPT and PaLM. |

